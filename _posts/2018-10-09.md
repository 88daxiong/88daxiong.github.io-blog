# 2018-10-09

## Deep Learning

### 线性回归VS罗辑回归

线性回归用来预测，逻辑回归用来分类。

线性回归是拟合函数，逻辑回归是预测函数

线性回归的参数计算方法是最小二乘法，逻辑回归的参数计算方法是梯度下降

最大的区别就在于他们的因变量不同

### 超参数

学习率、迭代次数、隐藏层数、激活函数选择、学习率调整方案、批尺寸大小、正则化方法等

### 方差与偏差

高方差带来过拟合，高方差可以通过添加正则化、减少模型冗余或使用更多的数据进行训练来解决；

高偏差带来欠拟合，选择更复杂的网络或不同的神经网络架构；

### 正则化

正则化用于解决高方差或过拟合

L1正则化是向目标函数添加正则化项，以减少参数的绝对值总和；

L2正则化是添加正则化项，从而减少参数平方的总和；

Dropout技术：随机丢弃一部分神经元，可防止过拟合。可设置一个保留率p，判断是否丢弃；

Bagging技术：是结合多个模型来降低误差的技术；

数据增强：通过向训练数据添加扰动或转换来人工增加训练数据集；通常对图像采用镜像，旋转，裁剪，色彩变化等

### ROC和AUC

ROC曲线：接收者操作曲线（receiver operating characteristic curve），是反映敏感性和特异性连续性变量的指标，ROC曲线上的每一个点都反映着对同一信号刺激的感受性；

横坐标：伪正类率（FPR），也即预测为正但实际是负的样本占总的负样本的概率；

纵坐标：真整类率（TPR），也即预测为正实际也是正的样本占总的正样本的概率；

所以该曲线必定过（0，0）和（1，1）这两个点；而且该曲线越靠近左上角越好

AUC曲线：AUC是一个概率值，当你随机挑选一个正样本和负样本，根据当前分类计算方法得到的score值将这个正样本排在负样本前面的概率值，就是AUC值；

AUC值越大的分类起，正确率越高

**为何要使用ROC？**

当测试集中的正负样本分布变化的时候，ROC曲线能依然保持不变。

### 深度学习结果指标解析

准确率（Accuracy）= (TP+TN)/(TP+FN+FP+TN)，即预测正确的样本（包括正样本和负样本）占整个样本的比例

精确率（Percision）=TP/(TP+FP)，即预测为正类的数据中，有多少是原本就是正类的比例

召回率（Recall） = TP/(TP+FN)，即对于所有的正类样本，有多少被预测为正类的比例

F1-score = 2\*R\*P/(R+P)，是精确率和召回率的调和平均

2/F1 = 1/P + 1/R



## Daily Life

和前人相比，我们大多数人的努力远远不够，甚至微不足道；

### 选择伴侣的几个建议

温柔，讨人喜欢；不能有卑劣，善妒的个性；是否讲卫生，是否勤快；



**what I cannot create, I do not understand**



